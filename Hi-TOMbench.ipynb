{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install and freeze required dependencies for ease of access\n",
    "%pip install pandas\n",
    "%pip install torch\n",
    "%pip install datasets\n",
    "%pip install transformers\n",
    "%pip install openai\n",
    "%pip install subprocess\n",
    "%pip install sys\n",
    "%pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Accuracy: 0.00%\n",
      "Responses with accuracy saved to hi_tom_responses_with_accuracy.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtptr\\AppData\\Local\\Temp\\ipykernel_23876\\2804423484.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset[\"ai_answer\"] = responses\n",
      "C:\\Users\\mtptr\\AppData\\Local\\Temp\\ipykernel_23876\\2804423484.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset[\"is_correct\"] = correctness\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from openai import OpenAI\n",
    "import re\n",
    "\n",
    "# Initialize\n",
    "client = OpenAI(api_key = \"api-key\")\n",
    "\n",
    "# Load\n",
    "hi_tom_dataset = load_dataset(\"Hi-ToM/Hi-ToM_Dataset\")\n",
    "df = hi_tom_dataset[\"train\"].to_pandas()\n",
    "subset = df.head(100)\n",
    "\n",
    "# Placeholder\n",
    "responses = []\n",
    "correctness = []\n",
    "\n",
    "# Parse\n",
    "def parse_ai_answer(response_content):\n",
    "    match = re.search(r\"(?:the correct answer is:\\s*[A-Z]\\.\\s*)(.+?)(?:\\.|$)\", response_content, re.IGNORECASE)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return response_content.strip()\n",
    "\n",
    "# Iterate through the subset\n",
    "for index, row in subset.iterrows():\n",
    "    question = row[\"question\"]\n",
    "    story = row[\"story\"]\n",
    "    correct_answer = row[\"answer\"]\n",
    "    choices = row.get(\"choices\", \"\")\n",
    "    prompt = (\n",
    "        f\"Read the following story and answer the multiple-choice question. Think step-by-step. \"\n",
    "        f\"Provide the answer first, and then explain it \\n\\n\"\n",
    "        f\"Story: {story}\\n\\n\"\n",
    "        f\"Question: {question}\\n\\n\"\n",
    "        f\"Choices: {choices}\\n\\n\"\n",
    "        f\"Note: You should assume the following. (1) An agent witnesses everything and every movement before exiting a room. \"\n",
    "        f\"(2) An agent A can infer another agent B’s mental state only if A and B have been in the same room, or have private or public interactions. \"\n",
    "        f\"(3) Note that every agent tends to lie. What a character tells others doesn’t affect their actual belief. \"\n",
    "        f\"An agent tends to trust an agent that exited the room later than themselves. The exit order is known to all agents. \"\n",
    "        f\"(4) Agents in private communications know that others won’t hear them, but they know that anyone can hear any public claims.\"\n",
    "    )\n",
    "    \n",
    "    # Call\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Extract\n",
    "    raw_ai_answer = response.choices[0].message.content\n",
    "    ai_answer = parse_ai_answer(raw_ai_answer)\n",
    "    responses.append(ai_answer)\n",
    "    \n",
    "    # \"Correctness\"\n",
    "    is_correct = ai_answer.strip().lower() == correct_answer.strip().lower()\n",
    "    correctness.append(is_correct)\n",
    "\n",
    "# Add the responses and correctness to the DataFrame\n",
    "subset[\"ai_answer\"] = responses\n",
    "subset[\"is_correct\"] = correctness\n",
    "\n",
    "# Calculate and print the total percentage of correct answers\n",
    "accuracy = sum(correctness) / len(correctness) * 100\n",
    "print(f\"Total Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Save the resulting DataFrame to a CSV file\n",
    "subset.to_csv(\"hi_tom_responses_with_accuracy.csv\", index=False)\n",
    "# Confirm\n",
    "print(\"Responses with accuracy saved to hi_tom_responses_with_accuracy.csv\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
